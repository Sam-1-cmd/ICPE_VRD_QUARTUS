import streamlit as st
import os
from PyPDF2 import PdfReader
from io import BytesIO
from reportlab.lib.pagesizes import A4
from reportlab.pdfgen import canvas
from reportlab.lib.utils import ImageReader
from datetime import datetime

# ‚Äî‚Äî NOUVEAUX IMPORTS POUR RAG LOCAL ‚Äî‚Äî
import glob
import faiss
import numpy as np
import fitz
from sentence_transformers import SentenceTransformer
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline

# === CONFIG PAGE ===
st.set_page_config(page_title="ICPE / VRD Analyzer", layout="centered", page_icon="üõ†Ô∏è")

# === STYLE ===
st.markdown(
    """
    <style>
    .stApp {
        background-image: url("https://cdn.dribbble.com/users/527451/screenshots/3115734/safetynow_frame1-drib.gif");
        background-size: cover;
        background-attachment: fixed;
        background-position: center;
    }
    .main .block-container {
        background-color: rgba(255,255,255,0.9);
        border-radius: 15px;
        padding: 2rem;
    }
    </style>
    """,
    unsafe_allow_html=True
)

# === BARRE LAT√âRALE ===
st.sidebar.title("üß≠ Navigation")
MODE = st.sidebar.radio("üß† Mode d'analyse :", ["D√©mo hors ligne", "API OpenAI (GPT)"])

st.sidebar.markdown("üìÇ **T√©l√©verse un document r√©glementaire**")
uploaded_file = st.sidebar.file_uploader("Fichier PDF", type=["pdf"], label_visibility="collapsed")

# Extraction du texte brut du PDF
pdf_text = ""
if uploaded_file is not None:
    st.sidebar.success(f"‚úÖ Fichier charg√© : {uploaded_file.name}")
    try:
        reader = PdfReader(uploaded_file)
        pdf_text = "\n".join([page.extract_text() or "" for page in reader.pages])
        with st.expander("üßæ Voir le contenu du PDF import√©"):
            st.write(pdf_text[:1000] + ("..." if len(pdf_text) > 1000 else ""))
    except Exception as e:
        st.sidebar.error(f"Erreur lors de la lecture du PDF : {e}")

# === EN-T√äTE ===
col1, col2 = st.columns([1, 5])
with col1:
    st.image("https://www.construction21.org/france/data/sources/users/20051/20230217094921-5quartuslogoversion1-noire.jpg", width=150)
with col2:
    st.markdown("## üõ†Ô∏è ICPE / VRD Analyzer")
    st.markdown("**Outil d'analyse r√©glementaire des projets VRD li√©s aux ICPE**")

st.markdown("---")
st.info("üëã Bienvenue ! D√©cris ici ta modification VRD pour √©valuer son impact r√©glementaire ICPE.")

# === SAISIE DE L'UTILISATEUR ===
st.markdown("### ‚úçÔ∏è D√©cris la modification VRD √† analyser")
with st.expander("üîç Besoin d'un exemple ?"):
    st.markdown("""
    **Exemple :**  
    D√©placement d'un bassin de r√©tention vers l'ouest, en dehors de la zone inondable,  
    pour lib√©rer l'acc√®s pompier. Le nouveau bassin aura une capacit√© de 60 000 m¬≥.
    """)

user_input = st.text_area(
    "Saisie de la modification VRD :",
    placeholder="D√©cris ici ta modification (ouvrage, zone, raison, impact...)",
    height=200
)

# === FONCTIONS UTILES RAG LOCAL ===
def chunk_text(text: str, size: int = 1000, overlap: int = 200):
    """D√©coupe en chunks de `size` caract√®res avec chevauchement."""
    chunks = []
    start = 0
    while start < len(text):
        end = min(start + size, len(text))
        chunks.append(text[start:end])
        start += size - overlap
    return chunks

@st.cache_resource(show_spinner=False)
def init_local_rag(text: str):
    """
    Construit :
      - la liste de chunks,
      - l'embeddeur et embeddings normalis√©s,
      - l'index FAISS,
      - le pipeline de g√©n√©ration Flan-T5-small (CPU).
    """
    # 1) chunking du PDF
    chunks = chunk_text(text)

    # 2) embeddings
    embedder = SentenceTransformer("all-MiniLM-L6-v2")
    embs = embedder.encode(chunks, convert_to_numpy=True, show_progress_bar=False)
    embs /= np.linalg.norm(embs, axis=1, keepdims=True)

    # 3) index FAISS (cosine via Inner-Product)
    index = faiss.IndexFlatIP(embs.shape[1])
    index.add(embs)

    # 4) pipeline Flan-T5-small CPU
    tokenizer = AutoTokenizer.from_pretrained("google/flan-t5-small")
    model     = AutoModelForSeq2SeqLM.from_pretrained("google/flan-t5-small").to("cpu")
    generator = pipeline(
        "text2text-generation",
        model=model,
        tokenizer=tokenizer,
        device=-1
    )

    return chunks, embedder, index, generator

# === BOUTON ANALYSE ===
result_text = ""
if st.button("üîç Analyser la situation"):
    if not user_input.strip():
        st.warning("‚ö†Ô∏è D√©cris d'abord ta modification VRD.")
    else:
        if MODE == "D√©mo hors ligne":
            if not pdf_text:
                st.error("‚ö†Ô∏è T√©l√©verse un document PDF pour le mode hors ligne.")
            else:
                st.info("üß™ Mode d√©monstration **local RAG**")
                chunks, embedder, index, generator = init_local_rag(pdf_text)

                # retrieval
                q_emb = embedder.encode([user_input], convert_to_numpy=True)
                q_emb /= np.linalg.norm(q_emb, axis=1, keepdims=True)
                _, ids = index.search(q_emb, 3)
                context = "\n\n".join(chunks[i] for i in ids[0])

                # few-shot + prompt compact
                example = (
                    "Exemple :\n"
                    "Contexte : D√©placement d‚Äôun bassin de 20 000 m¬≥ hors zone inondable.\n"
                    "Question : Quel texte s‚Äôapplique et quelle solution ?\n"
                    "1) Disposition l√©gale (art. R123-45 CE : ¬´ ‚Ä¶ ¬ª)\n"
                    "2) Proposition de solution : maintenir le volume, pr√©voir un talus √©tanche‚Ä¶\n\n"
                )
                local_prompt = (
                    example +
                    "Contexte : " + context + "\n"
                    "Question : " + user_input + "\n"
                    "üîí Ne r√©p√®te pas le contexte. R√©ponds UNIQUEMENT EN FRAN√áAIS, style EXPERT ICPE/VRD.\n"
                    "1) Disposition l√©gale (article + citation pr√©cise)\n"
                    "2) Proposition de solution concr√®te adapt√©e\n"
                    "### R√©ponse :"
                )

                # g√©n√©ration sans stop_token
                with st.spinner("‚åõ G√©n√©ration de la r√©ponse‚Ä¶"):
                    out = generator(
                        local_prompt,
                        max_new_tokens=256,
                        num_beams=4,
                        early_stopping=True,
                    )
                    raw = out[0]["generated_text"]

                # post-traitement pour ne garder que le c≈ìur de la r√©ponse
                import re
                filtered = "\n".join(
                    line for line in raw.splitlines()
                    # on coupe tout ce qui ressemble encore √† un exemple ou prompt
                    if not re.match(r'^(Exemple|Contexte|Question|üîí|1\)|2\))', line, flags=re.IGNORECASE)
                ).strip()

                result_text = filtered
                st.success("‚úÖ R√©ponse RAG locale :")
                st.markdown(result_text)

        else:  # API OpenAI (GPT)
            try:
                from dotenv import load_dotenv
                from openai import OpenAI
                load_dotenv()
                client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

                system_msg = (
                    "Tu es un EXPERT ICPE/VRD. R√âPONDS UNIQUEMENT EN FRAN√áAIS, "
                    "sans anglicismes ni traduction, et NE R√âP√àTE PAS le contexte."
                )
                messages = [
                    {"role": "system", "content": system_msg},
                    {"role": "user",   "content": user_input}
                ]
                if pdf_text:
                    messages.insert(1, {"role": "user", "content": f"Document de r√©f√©rence :\n{pdf_text[:2000]}"})

                response = client.chat.completions.create(
                    model="gpt-4",
                    messages=messages,
                    temperature=0.0,
                    max_tokens=512
                )
                result_text = response.choices[0].message.content.strip()
                st.success("‚úÖ R√©ponse g√©n√©r√©e par GPT :")
                st.markdown(result_text)

            except Exception as e:
                st.error(f"‚ùå Erreur lors de l'appel API : {e}")


# === G√âN√âRATION DE LA FICHE PDF ===
if user_input and result_text:
    def generate_pdf(user_input, result_text):
        buffer = BytesIO()
        c = canvas.Canvas(buffer, pagesize=A4)
        width, height = A4
        logo = ImageReader("https://www.galivel.com/media/full/nouveau_logo_quartus-5.jpg")
        logo_w, logo_h = 100, 40

        def wrap_lines(text, max_width):
            words = text.split()
            lines = []; cur = ""
            for w in words:
                test = w if not cur else f"{cur} {w}"
                if c.stringWidth(test) <= max_width:
                    cur = test
                else:
                    lines.append(cur); cur = w
            if cur: lines.append(cur)
            return lines

        # page 1 header/footer
        def draw_header_footer(page_num):
            c.setFont("Helvetica-Bold", 16)
            c.drawString(50, height - 50, "Fiche d'analyse ICPE / VRD")
            c.drawImage(logo, width - 150, height - 80, width=logo_w, height=logo_h, mask="auto")
            c.setFont("Helvetica", 10)
            c.drawString(50, height - 70, f"Date : {datetime.now():%d/%m/%Y %H:%M}")
            c.setFont("Helvetica-Oblique", 8)
            c.drawCentredString(width/2, 20, f"Page {page_num}")

        # √©crire le contenu
        draw_header_footer(1)
        y = height - 100
        c.setFont("Helvetica-Bold", 12); c.drawString(50, y, "‚úçÔ∏è Modification d√©crite :")
        text_obj = c.beginText(50, y - 20); text_obj.setFont("Helvetica", 10)
        for line in wrap_lines(user_input, width-100):
            text_obj.textLine(line)
        c.drawText(text_obj)

        y2 = text_obj.getY() - 30
        c.setFont("Helvetica-Bold", 12); c.drawString(50, y2, "‚úÖ Analyse r√©glementaire :")
        res_obj = c.beginText(50, y2 - 20); res_obj.setFont("Helvetica", 10)
        for line in wrap_lines(result_text, width-100):
            res_obj.textLine(line)
        c.drawText(res_obj)

        c.showPage(); c.save()
        buffer.seek(0)
        return buffer

    pdf_bytes = generate_pdf(user_input, result_text)
    st.download_button(
        label="üì• T√©l√©charger la fiche PDF",
        data=pdf_bytes,
        file_name="fiche_analyse_ICPE_VRD.pdf",
        mime="application/pdf",
        use_container_width=True
    )

# === PIED DE PAGE ===
st.markdown('<div class="bottom">¬© 2025 Quartus ¬∑ Tous droits r√©serv√©s.</div>', unsafe_allow_html=True)
